{"cells":[{"cell_type":"code","execution_count":3,"id":"86e8c8e8","metadata":{"id":"86e8c8e8"},"outputs":[],"source":["import os\n","import json\n","from collections import OrderedDict, defaultdict"]},{"cell_type":"code","execution_count":4,"id":"f0a2d6c2","metadata":{"id":"f0a2d6c2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","from sklearn.model_selection import GroupKFold\n","import matplotlib.pyplot as plt\n","from prettytable import PrettyTable\n","from tqdm.auto import tqdm\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":5,"id":"dbfce8fb","metadata":{"id":"dbfce8fb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n"]}],"source":["from mmseg.registry import DATASETS, TRANSFORMS, MODELS, METRICS\n","from mmseg.datasets import BaseSegDataset\n","from mmseg.models.segmentors import EncoderDecoder\n","from mmseg.models.decode_heads import ASPPHead, FCNHead, SegformerHead\n","from mmseg.models.utils.wrappers import resize\n","\n","\n","from mmengine.config import Config\n","from mmengine.dataset import Compose\n","from mmengine.runner import Runner, load_checkpoint\n","from mmengine.evaluator import BaseMetric\n","from mmengine.logging import MMLogger, print_log\n","from mmengine.structures import PixelData\n","\n","from mmcv.transforms import BaseTransform"]},{"cell_type":"code","execution_count":6,"id":"b9bdfd8a","metadata":{"id":"b9bdfd8a"},"outputs":[],"source":["# 데이터 경로를 입력하세요\n","\n","IMAGE_ROOT = \"train/DCM/\"\n","LABEL_ROOT = \"train/outputs_json/\""]},{"cell_type":"code","execution_count":7,"id":"c10ec100","metadata":{"id":"c10ec100"},"outputs":[],"source":["CLASSES = [\n","    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n","    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n","    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n","    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n","    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n","    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n","]"]},{"cell_type":"code","execution_count":8,"id":"808d4d86","metadata":{"id":"808d4d86"},"outputs":[],"source":["CLASS2IND = {v: i for i, v in enumerate(CLASSES)}"]},{"cell_type":"code","execution_count":9,"id":"14f20766","metadata":{"id":"14f20766"},"outputs":[],"source":["IND2CLASS = {v: k for k, v in CLASS2IND.items()}"]},{"cell_type":"code","execution_count":10,"id":"e41dcbce","metadata":{"id":"e41dcbce"},"outputs":[],"source":["pngs = {\n","    os.path.relpath(os.path.join(root, fname), start=IMAGE_ROOT)\n","    for root, _dirs, files in os.walk(IMAGE_ROOT)\n","    for fname in files\n","    if os.path.splitext(fname)[1].lower() == \".png\"\n","}\n","\n","jsons = {\n","    os.path.relpath(os.path.join(root, fname), start=LABEL_ROOT)\n","    for root, _dirs, files in os.walk(LABEL_ROOT)\n","    for fname in files\n","    if os.path.splitext(fname)[1].lower() == \".json\"\n","}"]},{"cell_type":"code","execution_count":11,"id":"8148c927","metadata":{"id":"8148c927"},"outputs":[],"source":["pngs = sorted(pngs)\n","jsons = sorted(jsons)"]},{"cell_type":"code","execution_count":12,"id":"8ce51812","metadata":{},"outputs":[],"source":["# Copyright (c) OpenMMLab. All rights reserved.\n","import warnings\n","\n","import torch.nn as nn\n","import torch.utils.checkpoint as cp\n","from mmcv.cnn import build_conv_layer, build_norm_layer, build_plugin_layer\n","from mmengine.model import BaseModule\n","from mmengine.utils.dl_utils.parrots_wrapper import _BatchNorm\n","\n","from mmseg.registry import MODELS\n","from mmseg.models.utils import ResLayer\n","\n","\n","class BasicBlock(BaseModule):\n","    \"\"\"Basic block for ResNet.\"\"\"\n","\n","    expansion = 1\n","\n","    def __init__(self,\n","                 inplanes,\n","                 planes,\n","                 stride=1,\n","                 dilation=1,\n","                 downsample=None,\n","                 style='pytorch',\n","                 with_cp=False,\n","                 conv_cfg=None,\n","                 norm_cfg=dict(type='BN'),\n","                 dcn=None,\n","                 plugins=None,\n","                 init_cfg=None):\n","        super().__init__(init_cfg)\n","        assert dcn is None, 'Not implemented yet.'\n","        assert plugins is None, 'Not implemented yet.'\n","\n","        self.norm1_name, norm1 = build_norm_layer(norm_cfg, planes, postfix=1)\n","        self.norm2_name, norm2 = build_norm_layer(norm_cfg, planes, postfix=2)\n","\n","        self.conv1 = build_conv_layer(\n","            conv_cfg,\n","            inplanes,\n","            planes,\n","            3,\n","            stride=stride,\n","            padding=dilation,\n","            dilation=dilation,\n","            bias=False)\n","        self.add_module(self.norm1_name, norm1)\n","        self.conv2 = build_conv_layer(\n","            conv_cfg, planes, planes, 3, padding=1, bias=False)\n","        self.add_module(self.norm2_name, norm2)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","        self.dilation = dilation\n","        self.with_cp = with_cp\n","\n","    @property\n","    def norm1(self):\n","        \"\"\"nn.Module: normalization layer after the first convolution layer\"\"\"\n","        return getattr(self, self.norm1_name)\n","\n","    @property\n","    def norm2(self):\n","        \"\"\"nn.Module: normalization layer after the second convolution layer\"\"\"\n","        return getattr(self, self.norm2_name)\n","\n","    def forward(self, x):\n","        \"\"\"Forward function.\"\"\"\n","\n","        def _inner_forward(x):\n","            identity = x\n","\n","            out = self.conv1(x)\n","            out = self.norm1(out)\n","            out = self.relu(out)\n","\n","            out = self.conv2(out)\n","            out = self.norm2(out)\n","\n","            if self.downsample is not None:\n","                identity = self.downsample(x)\n","\n","            out += identity\n","\n","            return out\n","\n","        if self.with_cp and x.requires_grad:\n","            out = cp.checkpoint(_inner_forward, x)\n","        else:\n","            out = _inner_forward(x)\n","\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(BaseModule):\n","    \"\"\"Bottleneck block for ResNet.\n","\n","    If style is \"pytorch\", the stride-two layer is the 3x3 conv layer, if it is\n","    \"caffe\", the stride-two layer is the first 1x1 conv layer.\n","    \"\"\"\n","\n","    expansion = 4\n","\n","    def __init__(self,\n","                 inplanes,\n","                 planes,\n","                 stride=1,\n","                 dilation=1,\n","                 downsample=None,\n","                 style='pytorch',\n","                 with_cp=False,\n","                 conv_cfg=None,\n","                 norm_cfg=dict(type='BN'),\n","                 dcn=None,\n","                 plugins=None,\n","                 init_cfg=None):\n","        super().__init__(init_cfg)\n","        assert style in ['pytorch', 'caffe']\n","        assert dcn is None or isinstance(dcn, dict)\n","        assert plugins is None or isinstance(plugins, list)\n","        if plugins is not None:\n","            allowed_position = ['after_conv1', 'after_conv2', 'after_conv3']\n","            assert all(p['position'] in allowed_position for p in plugins)\n","\n","        self.inplanes = inplanes\n","        self.planes = planes\n","        self.stride = stride\n","        self.dilation = dilation\n","        self.style = style\n","        self.with_cp = with_cp\n","        self.conv_cfg = conv_cfg\n","        self.norm_cfg = norm_cfg\n","        self.dcn = dcn\n","        self.with_dcn = dcn is not None\n","        self.plugins = plugins\n","        self.with_plugins = plugins is not None\n","\n","        if self.with_plugins:\n","            # collect plugins for conv1/conv2/conv3\n","            self.after_conv1_plugins = [\n","                plugin['cfg'] for plugin in plugins\n","                if plugin['position'] == 'after_conv1'\n","            ]\n","            self.after_conv2_plugins = [\n","                plugin['cfg'] for plugin in plugins\n","                if plugin['position'] == 'after_conv2'\n","            ]\n","            self.after_conv3_plugins = [\n","                plugin['cfg'] for plugin in plugins\n","                if plugin['position'] == 'after_conv3'\n","            ]\n","\n","        if self.style == 'pytorch':\n","            self.conv1_stride = 1\n","            self.conv2_stride = stride\n","        else:\n","            self.conv1_stride = stride\n","            self.conv2_stride = 1\n","\n","        self.norm1_name, norm1 = build_norm_layer(norm_cfg, planes, postfix=1)\n","        self.norm2_name, norm2 = build_norm_layer(norm_cfg, planes, postfix=2)\n","        self.norm3_name, norm3 = build_norm_layer(\n","            norm_cfg, planes * self.expansion, postfix=3)\n","\n","        self.conv1 = build_conv_layer(\n","            conv_cfg,\n","            inplanes,\n","            planes,\n","            kernel_size=1,\n","            stride=self.conv1_stride,\n","            bias=False)\n","        self.add_module(self.norm1_name, norm1)\n","        fallback_on_stride = False\n","        if self.with_dcn:\n","            fallback_on_stride = dcn.pop('fallback_on_stride', False)\n","        if not self.with_dcn or fallback_on_stride:\n","            self.conv2 = build_conv_layer(\n","                conv_cfg,\n","                planes,\n","                planes,\n","                kernel_size=3,\n","                stride=self.conv2_stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                bias=False)\n","        else:\n","            assert self.conv_cfg is None, 'conv_cfg must be None for DCN'\n","            self.conv2 = build_conv_layer(\n","                dcn,\n","                planes,\n","                planes,\n","                kernel_size=3,\n","                stride=self.conv2_stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                bias=False)\n","\n","        self.add_module(self.norm2_name, norm2)\n","        self.conv3 = build_conv_layer(\n","            conv_cfg,\n","            planes,\n","            planes * self.expansion,\n","            kernel_size=1,\n","            bias=False)\n","        self.add_module(self.norm3_name, norm3)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","\n","        if self.with_plugins:\n","            self.after_conv1_plugin_names = self.make_block_plugins(\n","                planes, self.after_conv1_plugins)\n","            self.after_conv2_plugin_names = self.make_block_plugins(\n","                planes, self.after_conv2_plugins)\n","            self.after_conv3_plugin_names = self.make_block_plugins(\n","                planes * self.expansion, self.after_conv3_plugins)\n","\n","    def make_block_plugins(self, in_channels, plugins):\n","        \"\"\"make plugins for block.\n","\n","        Args:\n","            in_channels (int): Input channels of plugin.\n","            plugins (list[dict]): List of plugins cfg to build.\n","\n","        Returns:\n","            list[str]: List of the names of plugin.\n","        \"\"\"\n","        assert isinstance(plugins, list)\n","        plugin_names = []\n","        for plugin in plugins:\n","            plugin = plugin.copy()\n","            name, layer = build_plugin_layer(\n","                plugin,\n","                in_channels=in_channels,\n","                postfix=plugin.pop('postfix', ''))\n","            assert not hasattr(self, name), f'duplicate plugin {name}'\n","            self.add_module(name, layer)\n","            plugin_names.append(name)\n","        return plugin_names\n","\n","    def forward_plugin(self, x, plugin_names):\n","        \"\"\"Forward function for plugins.\"\"\"\n","        out = x\n","        for name in plugin_names:\n","            out = getattr(self, name)(x)\n","        return out\n","\n","    @property\n","    def norm1(self):\n","        \"\"\"nn.Module: normalization layer after the first convolution layer\"\"\"\n","        return getattr(self, self.norm1_name)\n","\n","    @property\n","    def norm2(self):\n","        \"\"\"nn.Module: normalization layer after the second convolution layer\"\"\"\n","        return getattr(self, self.norm2_name)\n","\n","    @property\n","    def norm3(self):\n","        \"\"\"nn.Module: normalization layer after the third convolution layer\"\"\"\n","        return getattr(self, self.norm3_name)\n","\n","    def forward(self, x):\n","        \"\"\"Forward function.\"\"\"\n","\n","        def _inner_forward(x):\n","            identity = x\n","\n","            out = self.conv1(x)\n","            out = self.norm1(out)\n","            out = self.relu(out)\n","\n","            if self.with_plugins:\n","                out = self.forward_plugin(out, self.after_conv1_plugin_names)\n","\n","            out = self.conv2(out)\n","            out = self.norm2(out)\n","            out = self.relu(out)\n","\n","            if self.with_plugins:\n","                out = self.forward_plugin(out, self.after_conv2_plugin_names)\n","\n","            out = self.conv3(out)\n","            out = self.norm3(out)\n","\n","            if self.with_plugins:\n","                out = self.forward_plugin(out, self.after_conv3_plugin_names)\n","\n","            if self.downsample is not None:\n","                identity = self.downsample(x)\n","\n","            out += identity\n","\n","            return out\n","\n","        if self.with_cp and x.requires_grad:\n","            out = cp.checkpoint(_inner_forward, x)\n","        else:\n","            out = _inner_forward(x)\n","\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","# @MODELS.register_module()\n","class ResNet(BaseModule):\n","    \"\"\"ResNet backbone.\n","\n","    This backbone is the improved implementation of `Deep Residual Learning\n","    for Image Recognition <https://arxiv.org/abs/1512.03385>`_.\n","\n","    Args:\n","        depth (int): Depth of resnet, from {18, 34, 50, 101, 152}.\n","        in_channels (int): Number of input image channels. Default: 3.\n","        stem_channels (int): Number of stem channels. Default: 64.\n","        base_channels (int): Number of base channels of res layer. Default: 64.\n","        num_stages (int): Resnet stages, normally 4. Default: 4.\n","        strides (Sequence[int]): Strides of the first block of each stage.\n","            Default: (1, 2, 2, 2).\n","        dilations (Sequence[int]): Dilation of each stage.\n","            Default: (1, 1, 1, 1).\n","        out_indices (Sequence[int]): Output from which stages.\n","            Default: (0, 1, 2, 3).\n","        style (str): `pytorch` or `caffe`. If set to \"pytorch\", the stride-two\n","            layer is the 3x3 conv layer, otherwise the stride-two layer is\n","            the first 1x1 conv layer. Default: 'pytorch'.\n","        deep_stem (bool): Replace 7x7 conv in input stem with 3 3x3 conv.\n","            Default: False.\n","        avg_down (bool): Use AvgPool instead of stride conv when\n","            downsampling in the bottleneck. Default: False.\n","        frozen_stages (int): Stages to be frozen (stop grad and set eval mode).\n","            -1 means not freezing any parameters. Default: -1.\n","        conv_cfg (dict | None): Dictionary to construct and config conv layer.\n","            When conv_cfg is None, cfg will be set to dict(type='Conv2d').\n","            Default: None.\n","        norm_cfg (dict): Dictionary to construct and config norm layer.\n","            Default: dict(type='BN', requires_grad=True).\n","        norm_eval (bool): Whether to set norm layers to eval mode, namely,\n","            freeze running stats (mean and var). Note: Effect on Batch Norm\n","            and its variants only. Default: False.\n","        dcn (dict | None): Dictionary to construct and config DCN conv layer.\n","            When dcn is not None, conv_cfg must be None. Default: None.\n","        stage_with_dcn (Sequence[bool]): Whether to set DCN conv for each\n","            stage. The length of stage_with_dcn is equal to num_stages.\n","            Default: (False, False, False, False).\n","        plugins (list[dict]): List of plugins for stages, each dict contains:\n","\n","            - cfg (dict, required): Cfg dict to build plugin.\n","\n","            - position (str, required): Position inside block to insert plugin,\n","            options: 'after_conv1', 'after_conv2', 'after_conv3'.\n","\n","            - stages (tuple[bool], optional): Stages to apply plugin, length\n","            should be same as 'num_stages'.\n","            Default: None.\n","        multi_grid (Sequence[int]|None): Multi grid dilation rates of last\n","            stage. Default: None.\n","        contract_dilation (bool): Whether contract first dilation of each layer\n","            Default: False.\n","        with_cp (bool): Use checkpoint or not. Using checkpoint will save some\n","            memory while slowing down the training speed. Default: False.\n","        zero_init_residual (bool): Whether to use zero init for last norm layer\n","            in resblocks to let them behave as identity. Default: True.\n","        pretrained (str, optional): model pretrained path. Default: None.\n","        init_cfg (dict or list[dict], optional): Initialization config dict.\n","            Default: None.\n","\n","    Example:\n","        >>> from mmseg.models import ResNet\n","        >>> import torch\n","        >>> self = ResNet(depth=18)\n","        >>> self.eval()\n","        >>> inputs = torch.rand(1, 3, 32, 32)\n","        >>> level_outputs = self.forward(inputs)\n","        >>> for level_out in level_outputs:\n","        ...     print(tuple(level_out.shape))\n","        (1, 64, 8, 8)\n","        (1, 128, 4, 4)\n","        (1, 256, 2, 2)\n","        (1, 512, 1, 1)\n","    \"\"\"\n","\n","    arch_settings = {\n","        18: (BasicBlock, (2, 2, 2, 2)),\n","        34: (BasicBlock, (3, 4, 6, 3)),\n","        50: (Bottleneck, (3, 4, 6, 3)),\n","        101: (Bottleneck, (3, 4, 23, 3)),\n","        152: (Bottleneck, (3, 8, 36, 3))\n","    }\n","\n","    def __init__(self,\n","                 depth,\n","                 in_channels=3,\n","                 stem_channels=64,\n","                 base_channels=64,\n","                 num_stages=4,\n","                 strides=(1, 2, 2, 2),\n","                 dilations=(1, 1, 1, 1),\n","                 out_indices=(0, 1, 2, 3),\n","                 style='pytorch',\n","                 deep_stem=False,\n","                 avg_down=False,\n","                 frozen_stages=-1,\n","                 conv_cfg=None,\n","                 norm_cfg=dict(type='BN', requires_grad=True),\n","                 norm_eval=False,\n","                 dcn=None,\n","                 stage_with_dcn=(False, False, False, False),\n","                 plugins=None,\n","                 multi_grid=None,\n","                 contract_dilation=False,\n","                 with_cp=False,\n","                 zero_init_residual=True,\n","                 pretrained=None,\n","                 init_cfg=None):\n","        super().__init__(init_cfg)\n","        if depth not in self.arch_settings:\n","            raise KeyError(f'invalid depth {depth} for resnet')\n","\n","        self.pretrained = pretrained\n","        self.zero_init_residual = zero_init_residual\n","        block_init_cfg = None\n","        assert not (init_cfg and pretrained), \\\n","            'init_cfg and pretrained cannot be setting at the same time'\n","        if isinstance(pretrained, str):\n","            warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n","                          'please use \"init_cfg\" instead')\n","            self.init_cfg = dict(type='Pretrained', checkpoint=pretrained)\n","        elif pretrained is None:\n","            if init_cfg is None:\n","                self.init_cfg = [\n","                    dict(type='Kaiming', layer='Conv2d'),\n","                    dict(\n","                        type='Constant',\n","                        val=1,\n","                        layer=['_BatchNorm', 'GroupNorm'])\n","                ]\n","                block = self.arch_settings[depth][0]\n","                if self.zero_init_residual:\n","                    if block is BasicBlock:\n","                        block_init_cfg = dict(\n","                            type='Constant',\n","                            val=0,\n","                            override=dict(name='norm2'))\n","                    elif block is Bottleneck:\n","                        block_init_cfg = dict(\n","                            type='Constant',\n","                            val=0,\n","                            override=dict(name='norm3'))\n","        else:\n","            raise TypeError('pretrained must be a str or None')\n","\n","        self.depth = depth\n","        self.stem_channels = stem_channels\n","        self.base_channels = base_channels\n","        self.num_stages = num_stages\n","        assert num_stages >= 1 and num_stages <= 4\n","        self.strides = strides\n","        self.dilations = dilations\n","        assert len(strides) == len(dilations) == num_stages\n","        self.out_indices = out_indices\n","        assert max(out_indices) < num_stages\n","        self.style = style\n","        self.deep_stem = deep_stem\n","        self.avg_down = avg_down\n","        self.frozen_stages = frozen_stages\n","        self.conv_cfg = conv_cfg\n","        self.norm_cfg = norm_cfg\n","        self.with_cp = with_cp\n","        self.norm_eval = norm_eval\n","        self.dcn = dcn\n","        self.stage_with_dcn = stage_with_dcn\n","        if dcn is not None:\n","            assert len(stage_with_dcn) == num_stages\n","        self.plugins = plugins\n","        self.multi_grid = multi_grid\n","        self.contract_dilation = contract_dilation\n","        self.block, stage_blocks = self.arch_settings[depth]\n","        self.stage_blocks = stage_blocks[:num_stages]\n","        self.inplanes = stem_channels\n","\n","        self._make_stem_layer(in_channels, stem_channels)\n","\n","        self.res_layers = []\n","        for i, num_blocks in enumerate(self.stage_blocks):\n","            stride = strides[i]\n","            dilation = dilations[i]\n","            dcn = self.dcn if self.stage_with_dcn[i] else None\n","            if plugins is not None:\n","                stage_plugins = self.make_stage_plugins(plugins, i)\n","            else:\n","                stage_plugins = None\n","            # multi grid is applied to last layer only\n","            stage_multi_grid = multi_grid if i == len(\n","                self.stage_blocks) - 1 else None\n","            planes = base_channels * 2**i\n","            res_layer = self.make_res_layer(\n","                block=self.block,\n","                inplanes=self.inplanes,\n","                planes=planes,\n","                num_blocks=num_blocks,\n","                stride=stride,\n","                dilation=dilation,\n","                style=self.style,\n","                avg_down=self.avg_down,\n","                with_cp=with_cp,\n","                conv_cfg=conv_cfg,\n","                norm_cfg=norm_cfg,\n","                dcn=dcn,\n","                plugins=stage_plugins,\n","                multi_grid=stage_multi_grid,\n","                contract_dilation=contract_dilation,\n","                init_cfg=block_init_cfg)\n","            self.inplanes = planes * self.block.expansion\n","            layer_name = f'layer{i+1}'\n","            self.add_module(layer_name, res_layer)\n","            self.res_layers.append(layer_name)\n","\n","        self._freeze_stages()\n","\n","        self.feat_dim = self.block.expansion * base_channels * 2**(\n","            len(self.stage_blocks) - 1)\n","\n","    def make_stage_plugins(self, plugins, stage_idx):\n","        \"\"\"make plugins for ResNet 'stage_idx'th stage .\n","\n","        Currently we support to insert 'context_block',\n","        'empirical_attention_block', 'nonlocal_block' into the backbone like\n","        ResNet/ResNeXt. They could be inserted after conv1/conv2/conv3 of\n","        Bottleneck.\n","\n","        An example of plugins format could be :\n","        >>> plugins=[\n","        ...     dict(cfg=dict(type='xxx', arg1='xxx'),\n","        ...          stages=(False, True, True, True),\n","        ...          position='after_conv2'),\n","        ...     dict(cfg=dict(type='yyy'),\n","        ...          stages=(True, True, True, True),\n","        ...          position='after_conv3'),\n","        ...     dict(cfg=dict(type='zzz', postfix='1'),\n","        ...          stages=(True, True, True, True),\n","        ...          position='after_conv3'),\n","        ...     dict(cfg=dict(type='zzz', postfix='2'),\n","        ...          stages=(True, True, True, True),\n","        ...          position='after_conv3')\n","        ... ]\n","        >>> self = ResNet(depth=18)\n","        >>> stage_plugins = self.make_stage_plugins(plugins, 0)\n","        >>> assert len(stage_plugins) == 3\n","\n","        Suppose 'stage_idx=0', the structure of blocks in the stage would be:\n","            conv1-> conv2->conv3->yyy->zzz1->zzz2\n","        Suppose 'stage_idx=1', the structure of blocks in the stage would be:\n","            conv1-> conv2->xxx->conv3->yyy->zzz1->zzz2\n","\n","        If stages is missing, the plugin would be applied to all stages.\n","\n","        Args:\n","            plugins (list[dict]): List of plugins cfg to build. The postfix is\n","                required if multiple same type plugins are inserted.\n","            stage_idx (int): Index of stage to build\n","\n","        Returns:\n","            list[dict]: Plugins for current stage\n","        \"\"\"\n","        stage_plugins = []\n","        for plugin in plugins:\n","            plugin = plugin.copy()\n","            stages = plugin.pop('stages', None)\n","            assert stages is None or len(stages) == self.num_stages\n","            # whether to insert plugin into current stage\n","            if stages is None or stages[stage_idx]:\n","                stage_plugins.append(plugin)\n","\n","        return stage_plugins\n","\n","    def make_res_layer(self, **kwargs):\n","        \"\"\"Pack all blocks in a stage into a ``ResLayer``.\"\"\"\n","        return ResLayer(**kwargs)\n","\n","    @property\n","    def norm1(self):\n","        \"\"\"nn.Module: the normalization layer named \"norm1\" \"\"\"\n","        return getattr(self, self.norm1_name)\n","\n","    def _make_stem_layer(self, in_channels, stem_channels):\n","        \"\"\"Make stem layer for ResNet.\"\"\"\n","        if self.deep_stem:\n","            self.stem = nn.Sequential(\n","                build_conv_layer(\n","                    self.conv_cfg,\n","                    in_channels,\n","                    stem_channels // 2,\n","                    kernel_size=3,\n","                    stride=2,\n","                    padding=1,\n","                    bias=False),\n","                build_norm_layer(self.norm_cfg, stem_channels // 2)[1],\n","                nn.ReLU(inplace=True),\n","                build_conv_layer(\n","                    self.conv_cfg,\n","                    stem_channels // 2,\n","                    stem_channels // 2,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=1,\n","                    bias=False),\n","                build_norm_layer(self.norm_cfg, stem_channels // 2)[1],\n","                nn.ReLU(inplace=True),\n","                build_conv_layer(\n","                    self.conv_cfg,\n","                    stem_channels // 2,\n","                    stem_channels,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=1,\n","                    bias=False),\n","                build_norm_layer(self.norm_cfg, stem_channels)[1],\n","                nn.ReLU(inplace=True))\n","        else:\n","            self.conv1 = build_conv_layer(\n","                self.conv_cfg,\n","                in_channels,\n","                stem_channels,\n","                kernel_size=7,\n","                stride=2,\n","                padding=3,\n","                bias=False)\n","            self.norm1_name, norm1 = build_norm_layer(\n","                self.norm_cfg, stem_channels, postfix=1)\n","            self.add_module(self.norm1_name, norm1)\n","            self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    def _freeze_stages(self):\n","        \"\"\"Freeze stages param and norm stats.\"\"\"\n","        if self.frozen_stages >= 0:\n","            if self.deep_stem:\n","                self.stem.eval()\n","                for param in self.stem.parameters():\n","                    param.requires_grad = False\n","            else:\n","                self.norm1.eval()\n","                for m in [self.conv1, self.norm1]:\n","                    for param in m.parameters():\n","                        param.requires_grad = False\n","\n","        for i in range(1, self.frozen_stages + 1):\n","            m = getattr(self, f'layer{i}')\n","            m.eval()\n","            for param in m.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, x):\n","        \"\"\"Forward function.\"\"\"\n","        if self.deep_stem:\n","            x = self.stem(x)\n","        else:\n","            x = self.conv1(x)\n","            x = self.norm1(x)\n","            x = self.relu(x)\n","        x = self.maxpool(x)\n","        outs = []\n","        for i, layer_name in enumerate(self.res_layers):\n","            res_layer = getattr(self, layer_name)\n","            x = res_layer(x)\n","            if i in self.out_indices:\n","                outs.append(x)\n","        return tuple(outs)\n","\n","    def train(self, mode=True):\n","        \"\"\"Convert the model into training mode while keep normalization layer\n","        freezed.\"\"\"\n","        super().train(mode)\n","        self._freeze_stages()\n","        if mode and self.norm_eval:\n","            for m in self.modules():\n","                # trick: eval have effect on BatchNorm only\n","                if isinstance(m, _BatchNorm):\n","                    m.eval()\n","\n","\n","# @MODELS.register_module()\n","class ResNetV1c(ResNet):\n","    \"\"\"ResNetV1c variant described in [1]_.\n","\n","    Compared with default ResNet(ResNetV1b), ResNetV1c replaces the 7x7 conv in\n","    the input stem with three 3x3 convs. For more details please refer to `Bag\n","    of Tricks for Image Classification with Convolutional Neural Networks\n","    <https://arxiv.org/abs/1812.01187>`_.\n","    \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super().__init__(deep_stem=True, avg_down=False, **kwargs)\n","\n","\n","# @MODELS.register_module()\n","class ResNetV1d(ResNet):\n","    \"\"\"ResNetV1d variant described in [1]_.\n","\n","    Compared with default ResNet(ResNetV1b), ResNetV1d replaces the 7x7 conv in\n","    the input stem with three 3x3 convs. And in the downsampling block, a 2x2\n","    avg_pool with stride 2 is added before conv, whose stride is changed to 1.\n","    \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super().__init__(deep_stem=True, avg_down=True, **kwargs)\n"]},{"cell_type":"code","execution_count":13,"id":"086c097e","metadata":{},"outputs":[],"source":["norm_cfg = dict(type='SyncBN', requires_grad=True)\n","\n","backbone=dict(\n","        # type='ResNetV1c',\n","        depth=50,\n","        num_stages=4,\n","        out_indices=(0, 1, 2, 3),\n","        dilations=(1, 1, 2, 4),\n","        strides=(1, 2, 1, 1),\n","        norm_cfg=norm_cfg,\n","        norm_eval=False,\n","        style='pytorch',\n","        contract_dilation=True)"]},{"cell_type":"code","execution_count":14,"id":"c2c97272","metadata":{},"outputs":[],"source":["model = ResNetV1c(**backbone)"]},{"cell_type":"code","execution_count":15,"id":"95009f16","metadata":{},"outputs":[{"data":{"text/plain":["ResNetV1c(\n","  (stem): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (7): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","  )\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer2): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer3): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer4): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n",")\n","init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":16,"id":"3f4992fa","metadata":{},"outputs":[],"source":["input = torch.randn(1, 3, 2048, 2048)"]},{"cell_type":"code","execution_count":17,"id":"7dc30dde","metadata":{},"outputs":[],"source":["conv = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=2, padding=1)"]},{"cell_type":"code","execution_count":18,"id":"34993b9d","metadata":{},"outputs":[],"source":["output = conv(input)"]},{"cell_type":"code","execution_count":19,"id":"b719a29a","metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 8, 1024, 1024])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["output.shape"]},{"cell_type":"code","execution_count":20,"id":"4d099e13","metadata":{},"outputs":[],"source":["model.stem[0] = nn.Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"]},{"cell_type":"code","execution_count":21,"id":"3d2ef179","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[[ 0.4836, -0.0857,  0.4428,  ...,  0.3738,  0.0661,  0.9559],\n","          [ 0.1067,  0.1299, -0.7724,  ...,  0.6314,  0.5170,  0.7946],\n","          [-0.4343,  0.8852, -0.1339,  ..., -0.5221, -0.0383,  1.0081],\n","          ...,\n","          [ 0.3964, -0.2123,  1.5985,  ...,  0.2333,  0.2249,  0.0068],\n","          [-0.0733, -0.7195,  1.0045,  ...,  0.7773, -0.6902,  0.4015],\n","          [-0.5484,  0.5383,  0.4286,  ...,  0.3314,  0.5303,  0.2688]],\n","\n","         [[ 0.2761,  0.1802,  0.1959,  ..., -0.4208, -0.1206, -0.6639],\n","          [ 0.2613,  0.4021,  0.3806,  ..., -0.2605,  0.1409,  0.9815],\n","          [ 0.0963,  0.6272,  0.5400,  ..., -0.5965, -0.2719, -0.3434],\n","          ...,\n","          [ 0.2878,  0.0700, -1.3762,  ...,  0.2009, -0.5783, -0.1721],\n","          [-0.0955,  0.9459, -0.1833,  ..., -0.9290,  0.5356, -0.6697],\n","          [ 0.2192, -0.1333, -0.9825,  ..., -0.0401,  0.5183, -0.0632]],\n","\n","         [[-0.7030,  0.1192,  0.6190,  ...,  1.4228,  0.6654,  0.2167],\n","          [ 0.3619, -0.9174, -0.4085,  ...,  0.5781, -0.2834, -0.8150],\n","          [-0.4749, -0.5626, -0.4022,  ..., -0.2238,  0.4079,  0.2919],\n","          ...,\n","          [ 0.4900,  0.2343,  1.2023,  ..., -0.2423, -0.2753, -0.2351],\n","          [-0.3617, -1.1054, -0.4047,  ...,  0.5366, -0.8277,  0.6789],\n","          [-0.2063,  0.4632,  0.2776,  ...,  0.1415,  0.5532,  0.0130]],\n","\n","         ...,\n","\n","         [[-0.5269, -0.6279,  0.0297,  ..., -0.1893, -0.3800,  0.4028],\n","          [-0.3059, -0.4735,  0.0541,  ...,  0.9383,  0.4923, -0.7746],\n","          [-0.0822, -0.1654, -0.4530,  ...,  0.2245,  0.4895,  0.3183],\n","          ...,\n","          [-0.7912, -0.3771,  0.2426,  ..., -0.3007,  0.0844,  0.2567],\n","          [-0.2614, -0.1447, -0.9539,  ..., -0.5096,  0.3502,  0.3230],\n","          [-0.4961,  0.0873, -0.1082,  ...,  0.4754, -0.4504, -1.1000]],\n","\n","         [[-0.3535,  0.5800, -0.1336,  ..., -0.7323, -0.2204, -0.3912],\n","          [-0.5623, -0.8099,  0.9942,  ...,  1.2388,  0.5556, -0.8802],\n","          [ 0.1595, -0.7483, -0.6958,  ...,  0.2523,  0.2610, -0.9334],\n","          ...,\n","          [ 0.4825,  0.3430, -0.3193,  ..., -0.0855,  0.5625, -0.2614],\n","          [-0.1285,  2.1990,  0.1960,  ...,  0.2021,  0.5409,  0.1577],\n","          [ 0.7051, -0.4576, -0.3799,  ..., -0.0653, -0.4568, -0.8780]],\n","\n","         [[ 0.4190, -0.2694,  0.1161,  ...,  0.1145,  0.3075, -0.1890],\n","          [ 0.2681, -0.2411, -0.5592,  ...,  0.3097, -0.8621,  0.8221],\n","          [-0.1968,  1.0540, -0.0498,  ..., -0.0742,  0.1350,  0.9661],\n","          ...,\n","          [ 0.4077,  0.3429,  0.3968,  ...,  0.9451, -1.4589,  0.3334],\n","          [-0.0083, -0.5847,  1.1420,  ..., -0.2165,  0.4144,  0.4702],\n","          [ 0.1945,  0.4218,  0.1833,  ...,  0.6607,  0.7173,  0.1560]]]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","output.to('cuda')"]},{"cell_type":"code","execution_count":22,"id":"c2e26a25","metadata":{},"outputs":[{"data":{"text/plain":["ResNetV1c(\n","  (stem): Sequential(\n","    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (7): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","  )\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer2): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer3): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer4): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n",")\n","init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":23,"id":"de07c030","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.float32\n","torch.float32\n"]}],"source":["print(output.dtype)  # 입력 텐서 데이터 타입\n","print(next(model.parameters()).dtype)  # 모델 가중치 데이터 타입"]},{"cell_type":"code","execution_count":24,"id":"ad173dec","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["stem.0.weight is on cuda:0\n","stem.1.weight is on cuda:0\n","stem.1.bias is on cuda:0\n","stem.3.weight is on cuda:0\n","stem.4.weight is on cuda:0\n","stem.4.bias is on cuda:0\n","stem.6.weight is on cuda:0\n","stem.7.weight is on cuda:0\n","stem.7.bias is on cuda:0\n","layer1.0.conv1.weight is on cuda:0\n","layer1.0.bn1.weight is on cuda:0\n","layer1.0.bn1.bias is on cuda:0\n","layer1.0.conv2.weight is on cuda:0\n","layer1.0.bn2.weight is on cuda:0\n","layer1.0.bn2.bias is on cuda:0\n","layer1.0.conv3.weight is on cuda:0\n","layer1.0.bn3.weight is on cuda:0\n","layer1.0.bn3.bias is on cuda:0\n","layer1.0.downsample.0.weight is on cuda:0\n","layer1.0.downsample.1.weight is on cuda:0\n","layer1.0.downsample.1.bias is on cuda:0\n","layer1.1.conv1.weight is on cuda:0\n","layer1.1.bn1.weight is on cuda:0\n","layer1.1.bn1.bias is on cuda:0\n","layer1.1.conv2.weight is on cuda:0\n","layer1.1.bn2.weight is on cuda:0\n","layer1.1.bn2.bias is on cuda:0\n","layer1.1.conv3.weight is on cuda:0\n","layer1.1.bn3.weight is on cuda:0\n","layer1.1.bn3.bias is on cuda:0\n","layer1.2.conv1.weight is on cuda:0\n","layer1.2.bn1.weight is on cuda:0\n","layer1.2.bn1.bias is on cuda:0\n","layer1.2.conv2.weight is on cuda:0\n","layer1.2.bn2.weight is on cuda:0\n","layer1.2.bn2.bias is on cuda:0\n","layer1.2.conv3.weight is on cuda:0\n","layer1.2.bn3.weight is on cuda:0\n","layer1.2.bn3.bias is on cuda:0\n","layer2.0.conv1.weight is on cuda:0\n","layer2.0.bn1.weight is on cuda:0\n","layer2.0.bn1.bias is on cuda:0\n","layer2.0.conv2.weight is on cuda:0\n","layer2.0.bn2.weight is on cuda:0\n","layer2.0.bn2.bias is on cuda:0\n","layer2.0.conv3.weight is on cuda:0\n","layer2.0.bn3.weight is on cuda:0\n","layer2.0.bn3.bias is on cuda:0\n","layer2.0.downsample.0.weight is on cuda:0\n","layer2.0.downsample.1.weight is on cuda:0\n","layer2.0.downsample.1.bias is on cuda:0\n","layer2.1.conv1.weight is on cuda:0\n","layer2.1.bn1.weight is on cuda:0\n","layer2.1.bn1.bias is on cuda:0\n","layer2.1.conv2.weight is on cuda:0\n","layer2.1.bn2.weight is on cuda:0\n","layer2.1.bn2.bias is on cuda:0\n","layer2.1.conv3.weight is on cuda:0\n","layer2.1.bn3.weight is on cuda:0\n","layer2.1.bn3.bias is on cuda:0\n","layer2.2.conv1.weight is on cuda:0\n","layer2.2.bn1.weight is on cuda:0\n","layer2.2.bn1.bias is on cuda:0\n","layer2.2.conv2.weight is on cuda:0\n","layer2.2.bn2.weight is on cuda:0\n","layer2.2.bn2.bias is on cuda:0\n","layer2.2.conv3.weight is on cuda:0\n","layer2.2.bn3.weight is on cuda:0\n","layer2.2.bn3.bias is on cuda:0\n","layer2.3.conv1.weight is on cuda:0\n","layer2.3.bn1.weight is on cuda:0\n","layer2.3.bn1.bias is on cuda:0\n","layer2.3.conv2.weight is on cuda:0\n","layer2.3.bn2.weight is on cuda:0\n","layer2.3.bn2.bias is on cuda:0\n","layer2.3.conv3.weight is on cuda:0\n","layer2.3.bn3.weight is on cuda:0\n","layer2.3.bn3.bias is on cuda:0\n","layer3.0.conv1.weight is on cuda:0\n","layer3.0.bn1.weight is on cuda:0\n","layer3.0.bn1.bias is on cuda:0\n","layer3.0.conv2.weight is on cuda:0\n","layer3.0.bn2.weight is on cuda:0\n","layer3.0.bn2.bias is on cuda:0\n","layer3.0.conv3.weight is on cuda:0\n","layer3.0.bn3.weight is on cuda:0\n","layer3.0.bn3.bias is on cuda:0\n","layer3.0.downsample.0.weight is on cuda:0\n","layer3.0.downsample.1.weight is on cuda:0\n","layer3.0.downsample.1.bias is on cuda:0\n","layer3.1.conv1.weight is on cuda:0\n","layer3.1.bn1.weight is on cuda:0\n","layer3.1.bn1.bias is on cuda:0\n","layer3.1.conv2.weight is on cuda:0\n","layer3.1.bn2.weight is on cuda:0\n","layer3.1.bn2.bias is on cuda:0\n","layer3.1.conv3.weight is on cuda:0\n","layer3.1.bn3.weight is on cuda:0\n","layer3.1.bn3.bias is on cuda:0\n","layer3.2.conv1.weight is on cuda:0\n","layer3.2.bn1.weight is on cuda:0\n","layer3.2.bn1.bias is on cuda:0\n","layer3.2.conv2.weight is on cuda:0\n","layer3.2.bn2.weight is on cuda:0\n","layer3.2.bn2.bias is on cuda:0\n","layer3.2.conv3.weight is on cuda:0\n","layer3.2.bn3.weight is on cuda:0\n","layer3.2.bn3.bias is on cuda:0\n","layer3.3.conv1.weight is on cuda:0\n","layer3.3.bn1.weight is on cuda:0\n","layer3.3.bn1.bias is on cuda:0\n","layer3.3.conv2.weight is on cuda:0\n","layer3.3.bn2.weight is on cuda:0\n","layer3.3.bn2.bias is on cuda:0\n","layer3.3.conv3.weight is on cuda:0\n","layer3.3.bn3.weight is on cuda:0\n","layer3.3.bn3.bias is on cuda:0\n","layer3.4.conv1.weight is on cuda:0\n","layer3.4.bn1.weight is on cuda:0\n","layer3.4.bn1.bias is on cuda:0\n","layer3.4.conv2.weight is on cuda:0\n","layer3.4.bn2.weight is on cuda:0\n","layer3.4.bn2.bias is on cuda:0\n","layer3.4.conv3.weight is on cuda:0\n","layer3.4.bn3.weight is on cuda:0\n","layer3.4.bn3.bias is on cuda:0\n","layer3.5.conv1.weight is on cuda:0\n","layer3.5.bn1.weight is on cuda:0\n","layer3.5.bn1.bias is on cuda:0\n","layer3.5.conv2.weight is on cuda:0\n","layer3.5.bn2.weight is on cuda:0\n","layer3.5.bn2.bias is on cuda:0\n","layer3.5.conv3.weight is on cuda:0\n","layer3.5.bn3.weight is on cuda:0\n","layer3.5.bn3.bias is on cuda:0\n","layer4.0.conv1.weight is on cuda:0\n","layer4.0.bn1.weight is on cuda:0\n","layer4.0.bn1.bias is on cuda:0\n","layer4.0.conv2.weight is on cuda:0\n","layer4.0.bn2.weight is on cuda:0\n","layer4.0.bn2.bias is on cuda:0\n","layer4.0.conv3.weight is on cuda:0\n","layer4.0.bn3.weight is on cuda:0\n","layer4.0.bn3.bias is on cuda:0\n","layer4.0.downsample.0.weight is on cuda:0\n","layer4.0.downsample.1.weight is on cuda:0\n","layer4.0.downsample.1.bias is on cuda:0\n","layer4.1.conv1.weight is on cuda:0\n","layer4.1.bn1.weight is on cuda:0\n","layer4.1.bn1.bias is on cuda:0\n","layer4.1.conv2.weight is on cuda:0\n","layer4.1.bn2.weight is on cuda:0\n","layer4.1.bn2.bias is on cuda:0\n","layer4.1.conv3.weight is on cuda:0\n","layer4.1.bn3.weight is on cuda:0\n","layer4.1.bn3.bias is on cuda:0\n","layer4.2.conv1.weight is on cuda:0\n","layer4.2.bn1.weight is on cuda:0\n","layer4.2.bn1.bias is on cuda:0\n","layer4.2.conv2.weight is on cuda:0\n","layer4.2.bn2.weight is on cuda:0\n","layer4.2.bn2.bias is on cuda:0\n","layer4.2.conv3.weight is on cuda:0\n","layer4.2.bn3.weight is on cuda:0\n","layer4.2.bn3.bias is on cuda:0\n"]}],"source":["for name, param in model.named_parameters():\n","    print(f\"{name} is on {param.device}\")"]},{"cell_type":"code","execution_count":25,"id":"fc957baa","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["print(output.device)"]},{"cell_type":"code","execution_count":26,"id":"bd684be1","metadata":{},"outputs":[],"source":["output = output.to('cuda')"]},{"cell_type":"code","execution_count":27,"id":"de70fd15","metadata":{},"outputs":[],"source":["# output = model(output)"]},{"cell_type":"code","execution_count":28,"id":"e4e08ae4","metadata":{},"outputs":[{"data":{"text/plain":["ResNetV1c(\n","  (stem): Sequential(\n","    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (7): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","  )\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer2): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer3): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer4): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n",")\n","init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":29,"id":"d1dd38be","metadata":{},"outputs":[],"source":["from torch.nn.modules.batchnorm import SyncBatchNorm\n","\n","# SyncBatchNorm을 일반 BatchNorm으로 변환\n","def convert_sync_batchnorm_to_batchnorm(model):\n","    for name, module in model.named_children():\n","        if isinstance(module, SyncBatchNorm):\n","            setattr(model, name, torch.nn.BatchNorm2d(module.num_features))\n","        else:\n","            convert_sync_batchnorm_to_batchnorm(module)\n","\n","convert_sync_batchnorm_to_batchnorm(model)"]},{"cell_type":"code","execution_count":30,"id":"fa3c6af3","metadata":{},"outputs":[{"data":{"text/plain":["ResNetV1c(\n","  (stem): Sequential(\n","    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","  )\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer2): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer3): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer4): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n",")\n","init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":31,"id":"6ce5a955","metadata":{},"outputs":[{"data":{"text/plain":["ResNetV1c(\n","  (stem): Sequential(\n","    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","  )\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer2): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer3): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n","  (layer4): ResLayer(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n","  )\n",")\n","init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model.to('cuda')"]},{"cell_type":"code","execution_count":32,"id":"5b0e6861","metadata":{},"outputs":[],"source":["output = model(output)"]},{"cell_type":"code","execution_count":33,"id":"a80241b8","metadata":{},"outputs":[{"data":{"text/plain":["4"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["len(output)"]},{"cell_type":"code","execution_count":34,"id":"1b7a6cd5","metadata":{},"outputs":[],"source":["# Copyright (c) OpenMMLab. All rights reserved.\n","import torch\n","import torch.nn as nn\n","from mmcv.cnn import ConvModule, DepthwiseSeparableConvModule\n","\n","from mmseg.registry import MODELS\n","from mmseg.models.utils import resize\n","from mmseg.models.decode_heads.aspp_head import ASPPHead, ASPPModule\n","\n","\n","class DepthwiseSeparableASPPModule(ASPPModule):\n","    \"\"\"Atrous Spatial Pyramid Pooling (ASPP) Module with depthwise separable\n","    conv.\"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        for i, dilation in enumerate(self.dilations):\n","            if dilation > 1:\n","                self[i] = DepthwiseSeparableConvModule(\n","                    self.in_channels,\n","                    self.channels,\n","                    3,\n","                    dilation=dilation,\n","                    padding=dilation,\n","                    norm_cfg=self.norm_cfg,\n","                    act_cfg=self.act_cfg)\n","\n","\n","# @MODELS.register_module()\n","class DepthwiseSeparableASPPHead(ASPPHead):\n","    \"\"\"Encoder-Decoder with Atrous Separable Convolution for Semantic Image\n","    Segmentation.\n","\n","    This head is the implementation of `DeepLabV3+\n","    <https://arxiv.org/abs/1802.02611>`_.\n","\n","    Args:\n","        c1_in_channels (int): The input channels of c1 decoder. If is 0,\n","            the no decoder will be used.\n","        c1_channels (int): The intermediate channels of c1 decoder.\n","    \"\"\"\n","\n","    def __init__(self, c1_in_channels, c1_channels, **kwargs):\n","        super().__init__(**kwargs)\n","        assert c1_in_channels >= 0\n","        self.aspp_modules = DepthwiseSeparableASPPModule(\n","            dilations=self.dilations,\n","            in_channels=self.in_channels,\n","            channels=self.channels,\n","            conv_cfg=self.conv_cfg,\n","            norm_cfg=self.norm_cfg,\n","            act_cfg=self.act_cfg)\n","        if c1_in_channels > 0:\n","            self.c1_bottleneck = ConvModule(\n","                c1_in_channels,\n","                c1_channels,\n","                1,\n","                conv_cfg=self.conv_cfg,\n","                norm_cfg=self.norm_cfg,\n","                act_cfg=self.act_cfg)\n","        else:\n","            self.c1_bottleneck = None\n","        self.sep_bottleneck = nn.Sequential(\n","            DepthwiseSeparableConvModule(\n","                self.channels + c1_channels,\n","                self.channels,\n","                3,\n","                padding=1,\n","                norm_cfg=self.norm_cfg,\n","                act_cfg=self.act_cfg),\n","            DepthwiseSeparableConvModule(\n","                self.channels,\n","                self.channels,\n","                3,\n","                padding=1,\n","                norm_cfg=self.norm_cfg,\n","                act_cfg=self.act_cfg))\n","\n","    def forward(self, inputs):\n","        \"\"\"Forward function.\"\"\"\n","        x = self._transform_inputs(inputs)\n","        aspp_outs = [\n","            resize(\n","                self.image_pool(x),\n","                size=x.size()[2:],\n","                mode='bilinear',\n","                align_corners=self.align_corners)\n","        ]\n","        aspp_outs.extend(self.aspp_modules(x))\n","        aspp_outs = torch.cat(aspp_outs, dim=1)\n","        output = self.bottleneck(aspp_outs)\n","        if self.c1_bottleneck is not None:\n","            c1_output = self.c1_bottleneck(inputs[0])\n","            output = resize(\n","                input=output,\n","                size=c1_output.shape[2:],\n","                mode='bilinear',\n","                align_corners=self.align_corners)\n","            output = torch.cat([output, c1_output], dim=1)\n","        output = self.sep_bottleneck(output)\n","        output = self.cls_seg(output)\n","        return output\n"]},{"cell_type":"code","execution_count":35,"id":"cc57fd7b","metadata":{},"outputs":[],"source":["norm_cfg = dict(type='SyncBN', requires_grad=True)\n","\n","decode_head=dict(\n","        # type='DepthwiseSeparableASPPHead',\n","        in_channels=2048,\n","        in_index=3,\n","        channels=512,\n","        dilations=(1, 12, 24, 36),\n","        c1_in_channels=256,\n","        c1_channels=48,\n","        dropout_ratio=0.1,\n","        num_classes=29,\n","        norm_cfg=norm_cfg,\n","        align_corners=False,\n","        loss_decode=dict(\n","        type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))"]},{"cell_type":"code","execution_count":36,"id":"baa0ad26","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/data/ephemeral/home/level2-cv-semanticsegmentation-cv-06-lv3/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  warnings.warn(\n"]}],"source":["decoder = DepthwiseSeparableASPPHead(**decode_head)"]},{"cell_type":"code","execution_count":37,"id":"cfe6dec6","metadata":{},"outputs":[{"data":{"text/plain":["DepthwiseSeparableASPPHead(\n","  input_transform=None, ignore_index=255, align_corners=False\n","  (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n","  (conv_seg): Conv2d(512, 29, kernel_size=(1, 1), stride=(1, 1))\n","  (dropout): Dropout2d(p=0.1, inplace=False)\n","  (image_pool): Sequential(\n","    (0): AdaptiveAvgPool2d(output_size=1)\n","    (1): ConvModule(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activate): ReLU(inplace=True)\n","    )\n","  )\n","  (aspp_modules): DepthwiseSeparableASPPModule(\n","    (0): ConvModule(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activate): ReLU(inplace=True)\n","    )\n","    (1): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False)\n","        (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","    (2): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=2048, bias=False)\n","        (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","    (3): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=2048, bias=False)\n","        (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (bottleneck): ConvModule(\n","    (conv): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (activate): ReLU(inplace=True)\n","  )\n","  (c1_bottleneck): ConvModule(\n","    (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (activate): ReLU(inplace=True)\n","  )\n","  (sep_bottleneck): Sequential(\n","    (0): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(560, 560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=560, bias=False)\n","        (bn): SyncBatchNorm(560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(560, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","    (1): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","  )\n",")\n","init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["decoder.to('cuda')"]},{"cell_type":"code","execution_count":38,"id":"1b2f3830","metadata":{},"outputs":[],"source":["output = [tensor.to('cuda') for tensor in output]  # 리스트 내부의 각 텐서를 GPU로 이동"]},{"cell_type":"code","execution_count":39,"id":"8159e64d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'>\n","4\n","Tensor 0: shape=torch.Size([1, 256, 256, 256])\n","Tensor 1: shape=torch.Size([1, 512, 128, 128])\n","Tensor 2: shape=torch.Size([1, 1024, 128, 128])\n","Tensor 3: shape=torch.Size([1, 2048, 128, 128])\n"]}],"source":["print(type(output))\n","print(len(output))  \n","for idx, tensor in enumerate(output):\n","    print(f\"Tensor {idx}: shape={tensor.shape}\")"]},{"cell_type":"code","execution_count":40,"id":"4b3488f0","metadata":{},"outputs":[],"source":["import torch.nn.functional as F\n","c1_input = F.interpolate(output[0], size=(128, 128), mode='bilinear', align_corners=False)"]},{"cell_type":"code","execution_count":41,"id":"bffdac25","metadata":{},"outputs":[],"source":["inputs = [c1_input, output[1], output[2], output[3]]"]},{"cell_type":"code","execution_count":43,"id":"f13a556b","metadata":{},"outputs":[],"source":["from torch.nn.modules.batchnorm import SyncBatchNorm\n","\n","# SyncBatchNorm을 일반 BatchNorm으로 변환\n","def convert_sync_batchnorm_to_batchnorm(model):\n","    for name, module in model.named_children():\n","        if isinstance(module, SyncBatchNorm):\n","            setattr(model, name, torch.nn.BatchNorm2d(module.num_features))\n","        else:\n","            convert_sync_batchnorm_to_batchnorm(module)\n","\n","convert_sync_batchnorm_to_batchnorm(decoder)"]},{"cell_type":"code","execution_count":46,"id":"2ea60ef2","metadata":{},"outputs":[],"source":["from torch.nn import GroupNorm, BatchNorm2d, LayerNorm\n","\n","# BatchNorm 또는 LayerNorm을 GroupNorm으로 변환\n","def convert_to_groupnorm(model):\n","    for name, module in model.named_children():\n","        if isinstance(module, BatchNorm2d):\n","            num_channels = module.num_features\n","            # num_groups을 num_channels와 호환되도록 설정\n","            num_groups = min(32, num_channels) if num_channels % 32 == 0 else 1\n","            setattr(model, name, GroupNorm(num_groups=num_groups, num_channels=num_channels))\n","        elif isinstance(module, LayerNorm):\n","            num_channels = module.normalized_shape[0]\n","            num_groups = min(32, num_channels) if num_channels % 32 == 0 else 1\n","            setattr(model, name, GroupNorm(num_groups=num_groups, num_channels=num_channels))\n","        else:\n","            convert_to_groupnorm(module)\n","\n","# 모델에 적용\n","convert_to_groupnorm(decoder)"]},{"cell_type":"code","execution_count":47,"id":"e7b8e96b","metadata":{},"outputs":[{"data":{"text/plain":["DepthwiseSeparableASPPHead(\n","  input_transform=None, ignore_index=255, align_corners=False\n","  (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n","  (conv_seg): Conv2d(512, 29, kernel_size=(1, 1), stride=(1, 1))\n","  (dropout): Dropout2d(p=0.1, inplace=False)\n","  (image_pool): Sequential(\n","    (0): AdaptiveAvgPool2d(output_size=1)\n","    (1): ConvModule(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n","      (activate): ReLU(inplace=True)\n","    )\n","  )\n","  (aspp_modules): DepthwiseSeparableASPPModule(\n","    (0): ConvModule(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n","      (activate): ReLU(inplace=True)\n","    )\n","    (1): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False)\n","        (bn): GroupNorm(32, 2048, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","    (2): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=2048, bias=False)\n","        (bn): GroupNorm(32, 2048, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","    (3): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=2048, bias=False)\n","        (bn): GroupNorm(32, 2048, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (bottleneck): ConvModule(\n","    (conv): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n","    (activate): ReLU(inplace=True)\n","  )\n","  (c1_bottleneck): ConvModule(\n","    (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): GroupNorm(1, 48, eps=1e-05, affine=True)\n","    (activate): ReLU(inplace=True)\n","  )\n","  (sep_bottleneck): Sequential(\n","    (0): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(560, 560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=560, bias=False)\n","        (bn): GroupNorm(1, 560, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(560, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","    (1): DepthwiseSeparableConvModule(\n","      (depthwise_conv): ConvModule(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","        (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (pointwise_conv): ConvModule(\n","        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): GroupNorm(32, 512, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","  )\n",")\n","init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["decoder.to('cuda')"]},{"cell_type":"code","execution_count":48,"id":"ea58c77c","metadata":{},"outputs":[],"source":["output = decoder(output)"]},{"cell_type":"code","execution_count":49,"id":"c1c01aee","metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 29, 256, 256])"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["output.shape"]},{"cell_type":"code","execution_count":50,"id":"3759ae56","metadata":{},"outputs":[],"source":["upconv = nn.ConvTranspose2d(in_channels=29, out_channels=29, kernel_size=16, stride=8, padding=4)"]},{"cell_type":"code","execution_count":51,"id":"88ab9459","metadata":{},"outputs":[{"data":{"text/plain":["ConvTranspose2d(29, 29, kernel_size=(16, 16), stride=(8, 8), padding=(4, 4))"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["upconv.to('cuda')"]},{"cell_type":"code","execution_count":52,"id":"282e5a1d","metadata":{},"outputs":[],"source":["output1 = upconv(output)"]},{"cell_type":"code","execution_count":53,"id":"143f885b","metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 29, 2048, 2048])"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["output1.shape"]},{"cell_type":"code","execution_count":null,"id":"0164c288","metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":5}
